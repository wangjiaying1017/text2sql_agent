"""
å¯¼å…¥InfluxDB DDLåˆ°ESå’ŒQdrant

å°†influx_ddl_explanations.jsonä¸­çš„InfluxDB measurementä¿¡æ¯å¯¼å…¥åˆ°ESå’ŒQdrantï¼Œ
ä¸MySQLè¡¨ç»“æ„ä½¿ç”¨ç›¸åŒçš„å­˜å‚¨æ ¼å¼ã€‚
"""
import json
from pathlib import Path
from typing import Any

from scripts.import_to_es import ElasticsearchStore
from scripts.import_to_qdrant import QdrantStore


# é›†åˆ/ç´¢å¼•åç§°ï¼ˆä¸MySQLåˆ†å¼€å­˜å‚¨ï¼‰
INFLUXDB_ES_INDEX = "influxdb_measurement_schema"
INFLUXDB_QDRANT_COLLECTION = "influxdb_measurement_schema"


def load_influxdb_ddl(json_file: str = "influx_ddl_explanations.json") -> list[dict[str, Any]]:
    """
    åŠ è½½InfluxDB DDLæ–‡ä»¶ã€‚
    
    Args:
        json_file: JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        measurementåˆ—è¡¨
    """
    file_path = Path(json_file)
    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
    
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    return data.get("explanations", [])


def convert_to_schema_format(measurement: dict[str, Any]) -> dict[str, Any]:
    """
    å°†InfluxDB measurementä¿¡æ¯è½¬æ¢ä¸ºä¸MySQLç›¸åŒçš„schemaæ ¼å¼ã€‚
    
    Args:
        measurement: åŸå§‹measurementæ•°æ®
        
    Returns:
        ç»Ÿä¸€æ ¼å¼çš„schemaå­—å…¸
    """
    measurement_name = measurement.get("measurement_name", "")
    measurement_desc = measurement.get("measurement_description", "")
    
    # æ„å»ºåˆ—ä¿¡æ¯ï¼ˆtags + fieldsï¼‰
    columns = []
    column_names = []
    column_comments = []
    
    # å¤„ç†tags
    tags = measurement.get("tags", {})
    for tag_name, tag_desc in tags.items():
        columns.append({
            "name": tag_name,
            "type": "TAG",
            "comment": tag_desc,
        })
        column_names.append(tag_name)
        column_comments.append(tag_desc.split("ã€‚")[0] if tag_desc else "")  # å–ç¬¬ä¸€å¥ä½œä¸ºç®€çŸ­æ³¨é‡Š
    
    # å¤„ç†fields
    fields = measurement.get("fields", {})
    for field_name, field_desc in fields.items():
        # ä»æè¿°ä¸­æå–ç±»å‹
        field_type = "FIELD"
        if "integer" in field_desc.lower():
            field_type = "INTEGER"
        elif "float" in field_desc.lower():
            field_type = "FLOAT"
        elif "string" in field_desc.lower():
            field_type = "STRING"
        
        columns.append({
            "name": field_name,
            "type": field_type,
            "comment": field_desc,
        })
        column_names.append(field_name)
        column_comments.append(field_desc.split("ã€‚")[0] if field_desc else "")  # å–ç¬¬ä¸€å¥
    
    # æ„å»ºDDLå­—ç¬¦ä¸²ï¼ˆInfluxDBé£æ ¼çš„Schemaæè¿°ï¼‰
    ddl_parts = [f"-- Measurement: {measurement_name}"]
    ddl_parts.append(f"-- æè¿°: {measurement_desc}")
    ddl_parts.append("")
    ddl_parts.append("-- Tags (ç»´åº¦å­—æ®µï¼Œç”¨äºç´¢å¼•å’Œè¿‡æ»¤):")
    for tag_name, tag_desc in tags.items():
        ddl_parts.append(f"--   {tag_name}: {tag_desc[:100]}...")
    
    ddl_parts.append("")
    ddl_parts.append("-- Fields (æ•°å€¼å­—æ®µ):")
    for field_name, field_desc in fields.items():
        ddl_parts.append(f"--   {field_name}: {field_desc[:100]}...")
    
    full_ddl = "\n".join(ddl_parts)
    
    return {
        "table_name": measurement_name,  # ä½¿ç”¨table_nameä¿æŒä¸€è‡´
        "table_comment": measurement_desc,
        "database_type": "influxdb",  # æ ‡è®°ä¸ºInfluxDB
        "columns": columns,
        "column_names_str": " ".join(column_names),
        "column_comments_str": " ".join(column_comments),
        "full_ddl": full_ddl,
        # ä¿ç•™åŸå§‹ç»“æ„
        "tags": tags,
        "fields": fields,
    }


def import_to_es(
    measurements: list[dict[str, Any]],
    delete_existing: bool = False,
) -> int:
    """
    å¯¼å…¥åˆ°Elasticsearchã€‚
    
    Args:
        measurements: measurementåˆ—è¡¨
        delete_existing: æ˜¯å¦åˆ é™¤å·²å­˜åœ¨çš„ç´¢å¼•
        
    Returns:
        æˆåŠŸå¯¼å…¥çš„æ•°é‡
    """
    # è½¬æ¢æ ¼å¼
    schemas = [convert_to_schema_format(m) for m in measurements]
    
    # åˆ›å»ºESå­˜å‚¨ï¼ˆä½¿ç”¨ç‹¬ç«‹ç´¢å¼•ï¼‰
    store = ElasticsearchStore(index_name=INFLUXDB_ES_INDEX)
    store.create_index(delete_existing=delete_existing)
    
    # æ‰¹é‡å¯¼å…¥
    print(f"ğŸ“¥ å¯¼å…¥ {len(schemas)} ä¸ªmeasurementåˆ°ES...")
    count = store.bulk_index(schemas)
    
    print(f"âœ… æˆåŠŸå¯¼å…¥ {count} ä¸ªmeasurementåˆ°ES")
    return count


def import_to_qdrant(
    measurements: list[dict[str, Any]],
    delete_existing: bool = False,
) -> int:
    """
    å¯¼å…¥åˆ°Qdrantã€‚
    
    Args:
        measurements: measurementåˆ—è¡¨
        delete_existing: æ˜¯å¦åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
        
    Returns:
        æˆåŠŸå¯¼å…¥çš„æ•°é‡
    """
    # è½¬æ¢æ ¼å¼
    schemas = [convert_to_schema_format(m) for m in measurements]
    
    # åˆ›å»ºQdrantå­˜å‚¨ï¼ˆä½¿ç”¨ç‹¬ç«‹é›†åˆï¼‰
    store = QdrantStore(collection_name=INFLUXDB_QDRANT_COLLECTION)
    store.create_collection(delete_existing=delete_existing)
    
    # æ‰¹é‡å¯¼å…¥
    print(f"ğŸ“¥ å¯¼å…¥ {len(schemas)} ä¸ªmeasurementåˆ°Qdrant...")
    count = store.batch_upsert(schemas)
    
    print(f"âœ… æˆåŠŸå¯¼å…¥ {count} ä¸ªmeasurementåˆ°Qdrant")
    return count


def main():
    """ä¸»å‡½æ•°ã€‚"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å¯¼å…¥InfluxDB DDLåˆ°ESå’ŒQdrant")
    parser.add_argument(
        "-f", "--file",
        default="influx_ddl_explanations.json",
        help="InfluxDB DDL JSONæ–‡ä»¶è·¯å¾„ (é»˜è®¤: influx_ddl_explanations.json)"
    )
    parser.add_argument(
        "-d", "--delete",
        action="store_true",
        help="åˆ é™¤å·²å­˜åœ¨çš„ç´¢å¼•/é›†åˆåé‡æ–°åˆ›å»º"
    )
    parser.add_argument(
        "--es-only",
        action="store_true",
        help="åªå¯¼å…¥åˆ°ES"
    )
    parser.add_argument(
        "--qdrant-only",
        action="store_true",
        help="åªå¯¼å…¥åˆ°Qdrant"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½æ•°æ®
    print(f"ğŸ“‚ åŠ è½½æ–‡ä»¶: {args.file}")
    measurements = load_influxdb_ddl(args.file)
    print(f"ğŸ“Š å…± {len(measurements)} ä¸ªmeasurement")
    
    # å¯¼å…¥
    if args.es_only:
        import_to_es(measurements, delete_existing=args.delete)
    elif args.qdrant_only:
        import_to_qdrant(measurements, delete_existing=args.delete)
    else:
        # é»˜è®¤å¯¼å…¥åˆ°ä¸¤ä¸ªå­˜å‚¨
        import_to_es(measurements, delete_existing=args.delete)
        print()
        import_to_qdrant(measurements, delete_existing=args.delete)
    
    print("\nâœ¨ å¯¼å…¥å®Œæˆ!")


if __name__ == "__main__":
    main()
